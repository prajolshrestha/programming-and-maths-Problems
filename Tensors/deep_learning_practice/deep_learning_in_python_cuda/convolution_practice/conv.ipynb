{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 0., 1., 0.],\n",
       "          [0., 1., 0., 1.],\n",
       "          [1., 0., 1., 0.],\n",
       "          [0., 1., 0., 1.]]]),\n",
       " torch.Size([1, 4, 4]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.tensor([[[1.,0.,1.,0.],\n",
    "                     [0.,1.,0.,1.],\n",
    "                     [1.,0.,1.,0.],\n",
    "                     [0.,1.,0.,1.]]])\n",
    "input, input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.4755,  0.8696, -0.7003, -0.7234],\n",
       "          [-0.0666, -0.5618,  1.0350, -0.8542],\n",
       "          [ 1.7642, -0.2270,  1.2038, -1.7775],\n",
       "          [-0.7719, -0.6116,  1.4382,  0.4948]]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.randn(1,1,4,4)\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.nn.Conv2d(in_channels=1, out_channels=2, kernel_size=2, stride=(1,2), padding=1, padding_mode='zeros')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Conv2d(1, 2, kernel_size=(2, 2), stride=(1, 2))>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[[[-0.1625, -0.3999],\n",
       "           [ 0.0881,  0.0642]]],\n",
       " \n",
       " \n",
       "         [[[ 0.3618, -0.2580],\n",
       "           [-0.2408, -0.0924]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0822, -0.3977], requires_grad=True))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.weight, m.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.3111, -0.4917],\n",
       "           [-0.2493, -0.3431]]],\n",
       " \n",
       " \n",
       "         [[[ 0.4451, -0.1248],\n",
       "           [-0.1745, -0.1232]]]]),\n",
       " torch.Size([2, 1, 2, 2]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.weight.data, m.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2982,  0.2982,  0.4125],\n",
       "         [ 0.8386,  0.7266,  0.3005],\n",
       "         [ 0.2982,  0.3575,  0.4718],\n",
       "         [ 0.8386,  0.7266,  0.3005],\n",
       "         [ 0.4125,  0.4718,  0.4718]],\n",
       "\n",
       "        [[-0.0772, -0.0772,  0.2870],\n",
       "         [ 0.5266,  1.0114,  0.7718],\n",
       "         [-0.0772,  0.2659,  0.6302],\n",
       "         [ 0.5266,  1.0114,  0.7718],\n",
       "         [ 0.2870,  0.6302,  0.6302]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_map = m(input)\n",
    "feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original input size: torch.Size([1, 1, 2, 2])\n",
      "Padded input size: torch.Size([1, 1, 4, 6])\n",
      "Padded input tensor:\n",
      "[[3. 4. 3. 4. 3. 4.]\n",
      " [1. 2. 1. 2. 1. 2.]\n",
      " [3. 4. 3. 4. 3. 4.]\n",
      " [1. 2. 1. 2. 1. 2.]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Create a tensor representing your input data\n",
    "input_data = torch.tensor([\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "], dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # Add batch and channel dimensions\n",
    "\n",
    "# Print the original input size\n",
    "print(\"Original input size:\", input_data.shape)  # Should be (1, 1, 2, 2)\n",
    "\n",
    "# Define padding parameters\n",
    "padding = (1, 1, 1, 1)  # Padding of 2 on each side (left, right, top, bottom)\n",
    "padding = (2,2,1,1)\n",
    "# Apply padding using torch.nn.functional.pad with circular mode\n",
    "padded_input = F.pad(input_data, padding, mode='circular')\n",
    "\n",
    "# Print the padded input size\n",
    "print(\"Padded input size:\", padded_input.shape)  # Should be (1, 1, 6, 6)\n",
    "\n",
    "# Print the padded input tensor\n",
    "print(\"Padded input tensor:\")\n",
    "print(padded_input.squeeze().numpy())  # .squeeze() removes batch and channel dimensions for printing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellpose_git",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
