{"cells":[{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[[[ 1.9269,  1.4873,  0.9007],\n","          [-2.1055,  0.6784, -1.2345],\n","          [-0.0431, -1.6047, -0.7521]],\n","\n","         [[ 1.6487, -0.3925, -1.4036],\n","          [-0.7279, -0.5594, -0.7688],\n","          [ 0.7624,  1.6423, -0.1596]],\n","\n","         [[-0.4974,  0.4396, -0.7581],\n","          [ 1.0783,  0.8008,  1.6806],\n","          [ 1.2791,  1.2964,  0.6105]]],\n","\n","\n","        [[[ 1.3347, -0.2316,  0.0418],\n","          [-0.2516,  0.8599, -1.3847],\n","          [-0.8712, -0.2234,  1.7174]],\n","\n","         [[ 0.3189, -0.4245, -0.8140],\n","          [-0.7360, -0.8371, -0.9224],\n","          [ 1.8113,  0.1606,  0.3672]],\n","\n","         [[ 0.1754, -1.1845,  1.3835],\n","          [-1.2024,  0.7078, -1.0759],\n","          [ 0.5357,  1.1754,  0.5612]]]])"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["# Image example\n","N, C, H, W = 2, 3, 3, 3\n","torch.manual_seed(42)\n","input = torch.randn(N, C, H, W)\n","input"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[[[ 1.5402,  1.1496,  0.6284],\n","          [-2.0428,  0.4309, -1.2689],\n","          [-0.2102, -1.5977, -0.8402]],\n","\n","         [[ 1.2930, -0.5207, -1.4191],\n","          [-0.8187, -0.6690, -0.8551],\n","          [ 0.5055,  1.2873, -0.3138]],\n","\n","         [[-0.6139,  0.2186, -0.8456],\n","          [ 0.7862,  0.5396,  1.3213],\n","          [ 0.9646,  0.9800,  0.3705]]],\n","\n","\n","        [[[ 1.4005, -0.2895,  0.0054],\n","          [-0.3110,  0.8881, -1.5336],\n","          [-0.9796, -0.2806,  1.8133]],\n","\n","         [[ 0.3044, -0.4976, -0.9179],\n","          [-0.8337, -0.9428, -1.0348],\n","          [ 1.9147,  0.1336,  0.3566]],\n","\n","         [[ 0.1496, -1.3176,  1.4531],\n","          [-1.3370,  0.7241, -1.2004],\n","          [ 0.5383,  1.2285,  0.5659]]]], grad_fn=<NativeLayerNormBackward0>)"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["# Normalize over the last three dimensions\n","# i.e. the channel and spatial dimensions\n","layer_norm = nn.LayerNorm([C,H,W], elementwise_affine=True)\n","\n","# (Batch_size, channel, height, width) --> (batch_size, channel, heigh, width)\n","normalized = layer_norm(input)\n","normalized"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean and std of input image:\n","Image 0:\n","Mean: 0.193514\n","Std:  1.146888\n","Image 1:\n","Mean: 0.036716\n","Std:  0.944496\n","Mean and std of input image after layernorm:\n","Image 0:\n","Mean: -0.000000\n","Std:  1.019045\n","Image 1:\n","Mean: 0.000000\n","Std:  1.019043\n"]}],"source":["print('Mean and std of input image:')\n","for i in range(N):\n","    img_s = input[i].flatten()\n","    print(f\"Image {i}:\")\n","    print(f\"Mean: {img_s.mean():.6f}\")\n","    print(f\"Std:  {img_s.std():.6f}\")\n","\n","print('Mean and std of input image after layernorm:')\n","for i in range(N):\n","    img_stats = normalized[i].flatten()\n","    print(f\"Image {i}:\")\n","    print(f\"Mean: {img_stats.mean():.6f}\")\n","    print(f\"Std:  {img_stats.std():.6f}\")"]}],"metadata":{"kernelspec":{"display_name":"cellpose_gui","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":2}
